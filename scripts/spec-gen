#!/usr/bin/env python3
import argparse, json, os, sys, re
from typing import List, Tuple, Dict, Any, Optional
from llama_index.core.base.llms.types import ChatMessage, MessageRole
from mage.gen_config import get_llm, get_exp_setting, set_exp_setting
from mage.log_utils import get_logger
from mage.utils import reformat_json_string
from mage.token_counter import TokenCounter

logger = get_logger(__name__)
settings = get_exp_setting()

EXAMPLE_SPEC = """\
I would like you to implement a module named TopModule with the following
interface. All input and output ports are one bit unless otherwise
specified.

 - input  clk
 - input  in
 - input  reset
 - output out_byte (8 bits)
 - output done

In many (older) serial communications protocols, each data byte is sent
along with a start bit and a stop bit, to help the receiver delimit bytes
from the stream of bits. One common scheme is to use one start bit (0), 8
data bits, and 1 stop bit (1). The line is also at logic 1 when nothing
is being transmitted (idle). Design a finite state machine that will
identify when bytes have been correctly received when given a stream of
bits. It needs to identify the start bit, wait for all 8 data bits, then
verify that the stop bit was correct. The module will also output the
correctly-received data byte. out_byte needs to be valid when done is
1, and is don't-care otherwise. If the stop bit does not appear when
expected, the FSM must wait until it finds a stop bit before attempting
to receive the next byte. Include a active-high synchronous reset. Note
that the serial protocol sends the least significant bit first. It should
assert done each time it finds a stop bit. Assume all sequential logic is
triggered on the positive edge of the clock.
"""

SYSTEM_PROMPT = """
You are an expert hardware specification writer. Produce a clear, standalone
**specification document** for an RTL module **without leaking implementation details**
from any provided reference RTL. The spec must:
- Describe external behavior and interfaces (not the implementation).
- Be detailed and unambiguous (longer specs are fine).
- Avoid code, internal state names, or micro-architecture hints.

Cover:
1) Overview & assumptions.
2) Interface (signals, dir, width, reset/polarity, timing).
3) Protocols/handshakes (valid/ready, AXI/AXI-Lite, req/rsp).
4) Behavioral requirements (corner cases, reset, backpressure, ordering, latency guarantees if applicable, errors).
5) Configuration parameters visible at the boundary (names, ranges, semantics).
6) Throughput/latency expectations at a spec level.
7) Clocking/reset domains and constraints.
8) Example timing/truth tables (no code).

NEVER include implementation specifics gleaned from the RTL (FSM encodings, stage counts, pragmas, internal signal names that aren't externally mandated).
Use the RTL only to infer intent and external requirements. Output Markdown only.
"""

USER_RTL_PROMPT_TEMPLATE = """
Write a **specification document** for a module to be designed, based on the behavior
you can infer from the following reference RTL. The spec must not reveal
implementation details from the reference RTL; treat it only as a hint to understand intent.

Target module name: {target_name}

### Short exemplar spec (style only)
```
{example_spec}
```

### Your task
- Produce a more detailed, production-quality spec than the exemplar.
- Include an interface list with directions, widths, reset polarities, and timing.
- Clearly describe protocols (valid/ready, AXI(-Lite), req/rsp, etc.).
- Clarify configuration parameters & constraints visible at the interface.
- Define behavior on reset, backpressure, invalid/exceptional inputs.
- Avoid micro-architectural/implementation-specific guidance.
- Do not include a title for the specification document.

### Provided Reference RTL
```systemverilog
{rtl_text}
```

Return only the final specification in Markdown. Do not include code.

[NAMING CONVENTION]

1. In the specification you generate, you must name the top level to be
designed "TopModule". So never mention the specific name of the module you read
from the reference RTL.
2. Always introduce the spec with "Design a module called TopModule. This
module [...]". This way, the RTL designer (human or AI-based) knows exactly how
to call the module. In the remainder, you describe what the module does
(specifications), and when you refer to it, you always call it "TopModule".
"""

JSON_SYSTEM_PROMPT = """You are an expert RTL interface summarizer.
Your task is to read a SystemVerilog source file and output a STRICT JSON object ONLY
(no markdown, no backticks, no prose) for the module whose name is provided
in the user message. You must extract ONLY that module and ignore any others.

Do not include implementation internals (FSM encodings, internal signals, pragmas).
Output VALID JSON only. No comments. No trailing commas. Use basic types only.

JSON schema (exact keys):
{
  "module_name": "<string>",
  "parameters": [
    {
      "name": "<string>",
      "type": "<string or null>",
      "default": "<string or null>"
    }
  ],
  "ports": [
    {
      "name": "<string>",
      "type": "logic" | "wire" | null,
      "direction": "input" | "output" | "inout",
      "signed": true | false,
      "type_ref": "<string or null>",
      "modport": "<string or null>",
      "packed_dims": [
        { "msb": "<string>", "lsb": "<string>" }
      ],
      "unpacked_dims": [
        { "size": "<string>" }
        or { "msb": "<string>", "lsb": "<string>" }
      ]
    }
  ],
  "description": {
    "function": "<string>",
    "protocols": "<string>"
  },
  "keywords": ["<string>", "..."]
}

[RULES]

1) Module selection
- Extract only the module whose name exactly matches the user-provided module name (case-sensitive).
- Ignore other modules, interfaces, packages, and all implementation internals.

2) Parameters
- Include both value parameters (`parameter`) and type parameters (`parameter type`) from the module header. Include `localparam` only if it appears in the ANSI header list.
- For value parameters:
  - "name": identifier.
  - "type": textual declared type if present (e.g., "int unsigned", "logic [7:0]"), else null.
  - "default": exact textual default expression, else null.
- For type parameters (`parameter type T = ...`):
  - "name": identifier of the type parameter.
  - "type": the literal string "type".
  - "default": default type text (e.g., "logic [7:0]") or null if unspecified.
- Preserve declaration order as written in the header.

3) Ports
- Use ANSI-style information from the module header; if non-ANSI is used, merge direction/type/dims from subsequent declarations.
- Split multi-declarators into separate entries (e.g., `input logic a, b;` ? two port objects).
- "name": port identifier.
- "direction": "input" | "output" | "inout" exactly as declared.
- Determine kind vs reference:
  - If declared with a built-in/net/var type, set "type" to "logic" (default for variables/unspecified/var/logic/reg) or "wire" (for explicit net types like wire/tri/uwire). Set "type_ref": null, "modport": null.
  - If an interface instance: set "type": null, "type_ref" = interface name, "modport" = modport name or null.
  - If a typedef is used (e.g., `my_t p`): set "type": null, "type_ref": "my_t", "modport": null.
- "signed": true only if the declaration includes `signed`; false otherwise (applies to the packed element type).
- Dimensions (verbatim, outermost?innermost):
  - "packed_dims": one object per packed slice next to the type, each as { "msb": "<expr>", "lsb": "<expr>" }.
  - "unpacked_dims": one object per dimension after the identifier; use { "size": "<expr>" } for `[N]` or { "msb": "<expr>", "lsb": "<expr>" } for `[M:L]`.
- If no dimensions, both arrays are [].
- Preserve port order.

4) Text fidelity
- Keep expressions verbatim strings; do not evaluate or simplify. Minimal whitespace normalization only (trim ends).

5) Disambiguation
- If kind is omitted in an input/output/inout declaration and it is variable-like, choose "logic".
- If an explicit net type is used, choose "wire".
- For interfaces, never place ranges in "packed_dims"; only "unpacked_dims" are allowed after the instance name.
- If a typedef appears with ranges:
  - If written as `my_t [N-1:0] p`, record "type_ref": "my_t" and put `[N-1:0]` into "packed_dims".
  - If written as `my_t p [N]`, record "type_ref": "my_t" and put `[N]` into "unpacked_dims".

6) Description and keywords
- "description.function": one concise sentence summarizing the module's purpose (from comments or reasonable inference).
- "description.protocols": comma-separated protocol/bus names mentioned (e.g., "AXI4-Stream, APB"), or empty string.
- "keywords": short, relevant terms (module role, buses, handshake signals). No duplicates.

7) Output format
- Output a single JSON object conforming exactly to the schema above.
- No markdown, no backticks, no comments, no trailing commas.
"""

def _build_json_user_prompt_for_named_top(rtl_text: str, top_module_name: str) -> str:
    return f"""
Target top module name: {top_module_name}

Extract ONLY the module with this exact name from the SystemVerilog text below.
Ignore any other modules.

Return a single JSON object following the exact schema described by the system message.

SystemVerilog file content starts below delimited by ===SV===
===SV===
{rtl_text}
===SV===
"""

def md_to_txt(md: str) -> str:
    """Tiny Markdown ? plain text cleaner (safe for LLM ingestion)."""
    txt = md
    # strip fenced code blocks (keep their inner text)
    txt = re.sub(r"```[\s\S]*?```",
                 lambda m: re.sub(r"^```.*\n|\n```$", "", m.group(0), flags=re.M),
                 txt)
    # headers, emphasis (keep underscores)
    txt = re.sub(r"^#{1,6}\s*", "", txt, flags=re.M)
    txt = txt.replace("**", "").replace("*", "")
    # inline code
    txt = txt.replace("`", "")
    # links: [text](url) ? text (url)
    txt = re.sub(r"\[([^\]]+)\]\(([^)]+)\)", r"\1 (\2)", txt)
    # tables & blockquotes
    txt = txt.replace("|", " ")
    txt = re.sub(r"^\s*>\s?", "", txt, flags=re.M)
    # collapse blank lines
    txt = re.sub(r"\n{3,}", "\n\n", txt).strip()
    return txt

def _read(path: str) -> str:
    with open(path, "r", encoding="utf-8", errors="replace") as f:
        return f.read()

def _soft_trim(counter: TokenCounter, parts: List[Tuple[str,int]], budget: int) -> List[str]:
    """Greedily trims longest part by ~10% until within budget; each part keeps at least its reserve."""
    ss, rs = [p for p,_ in parts], [r for _,r in parts]
    cnts = [counter.count(s) for s in ss]
    if sum(cnts) <= budget: return ss
    import math
    MINC=128
    while sum(cnts) > budget:
        i = max(range(len(cnts)), key=lambda k: cnts[k])
        floor = max(rs[i], MINC)
        if all(c <= max(r, MINC) for c,r in zip(cnts,rs)): break
        if cnts[i] <= floor:
            cands=[k for k,c in enumerate(cnts) if c>max(rs[k],MINC)]
            if not cands: break
            i=max(cands, key=lambda k: cnts[k])
        new_len=max(floor,int(math.floor(cnts[i]*0.9)))
        ratio=new_len/max(cnts[i],1)
        cut=max(1,int(len(ss[i])*ratio))
        ss[i]=ss[i][:cut]; cnts[i]=counter.count(ss[i])
    return ss

def _validate_and_optionally_fix_json_with_llm(history: List[ChatMessage],
                                               llm,
                                               max_trials: int = 3) -> Dict[str, Any]:
    local_tc = TokenCounter(llm)
    #local_tc.set_tpm_limit(32000)
    local_tc.set_cur_tag("RTL_JSON_Spec")
    response = None
    for _ in range(max_trials):
        response, _cnt = local_tc.count_chat(history, llm=llm)
        raw = (response.message.content or "").strip()
        try:
            return json.loads(raw, strict=False)
        except json.decoder.JSONDecodeError as e:
            err = ChatMessage(
                role=MessageRole.USER,
                content=f"Json Decode Error: {str(e)}\\n"
                        f"Please return ONLY valid JSON per the schema. "
                        f"No prose, no backticks, no comments."
            )
            history.extend([response.message, err])
    raise ValueError(f"Json Decode Error when decoding: {response.message.content if response else '(no response)'}")

def generate_rtl_json_spec(llm,
                           rtl_path: str,
                           rtl_text: str,
                           top_module_name: str,
                           out_path: Optional[str] = None,
                           max_trials: int = 3) -> str:
    sys_msg = ChatMessage(role=MessageRole.SYSTEM, content=JSON_SYSTEM_PROMPT)
    user_msg = ChatMessage(role=MessageRole.USER,
                           content=_build_json_user_prompt_for_named_top(rtl_text, top_module_name))
    history: List[ChatMessage] = [sys_msg, user_msg]
    json_obj = _validate_and_optionally_fix_json_with_llm(history, llm, max_trials=max_trials)

    pattern = re.compile(
        rf"\bmodule\s+{re.escape(top_module_name)}\b[\s\S]*?\bendmodule\b",
        re.MULTILINE
    )
    match = pattern.search(rtl_text)
    if match:
        reuse_code = match.group(0)
    else:
        logger.warning(f"Top module {top_module_name} not found in RTL text; using full RTL for reuse.")
        reuse_code = rtl_text

    content_entry = {
        "consult": rtl_text,   # full file
        "reuse": reuse_code    # only top module
    }

    if isinstance(json_obj, dict):
        if "keywords" in json_obj:
            reordered = {}
            for k, v in json_obj.items():
                reordered[k] = v
                if k == "keywords":
                    reordered["content"] = content_entry
            json_obj = reordered
        else:
            json_obj["content"] = content_entry
    else:
        # Fallback: ensure we still emit a dict with the RTL source
        json_obj = {
            "extracted": json_obj,
            "content": content_entry,
        }

    if out_path is None:
        base_dir = os.path.dirname(os.path.abspath(rtl_path))
        base_name = os.path.splitext(os.path.basename(rtl_path))[0]
        out_path = os.path.join(base_dir, f"{base_name}.module.json")

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(json_obj, f, indent=2)

    return out_path

def main():
    ap = argparse.ArgumentParser(description="Generate a spec (Markdown) from tb.sv + rtl_golden.sv via LLM, no implementation leakage.")
    ap.add_argument("--rtl", required=True, help="Path to the reference RTL file (SystemVerilog)")
    ap.add_argument("--top", required=True, help="Explicit top-level module name (in RTL) for JSON extraction")
    ap.add_argument("--out", default="spec.md", help="Output filename (default: spec.md)")
    ap.add_argument("--provider", default="openai", help="LLM provider (e.g. openai, anthropic, vertex, etc.)")
    ap.add_argument("--model", default="gpt-4o-2024-08-06", help="LLM model name")
    ap.add_argument("--key-cfg-path", default="./key.cfg", help="Path to API keys configuration file")
    ap.add_argument("--max-token", type=int, default=8192, help="Maximum tokens per LLM response")
    ap.add_argument("--tokens", type=int, default=12000, help="Total token budget for prompt+inputs")
    ap.add_argument("--temperature", type=float, default=0.85, help="LLM sampling temperature")
    ap.add_argument("--top-p", type=float, default=0.95, help="LLM nucleus sampling parameter")
    ap.add_argument("--tag", default="spec_gen", help="Tag for token counter logging")
    ap.add_argument("--emit", choices=["bench", "lib", "all"], default="all", help="Artifacts to emit: bench (md/txt), lib (json), or all (default).")
    args = ap.parse_args()

    emit = args.emit
    gen_bench = emit in ("bench", "all")
    gen_lib = emit in ("lib", "all")

    out_dir = os.path.dirname(os.path.abspath(args.out)) or "."
    os.makedirs(out_dir, exist_ok=True)
    base = os.path.splitext(os.path.basename(args.out))[0]
    out_md = os.path.join(out_dir, base + ".md")
    out_txt = os.path.join(out_dir, base + ".txt")
    out_json = os.path.join(out_dir, base + ".json")

    if not os.path.isfile(args.rtl):
        print("RTL file not found.", file=sys.stderr); sys.exit(1)

    set_exp_setting(temperature=args.temperature, top_p=args.top_p)
    llm = get_llm(model=args.model, cfg_path=args.key_cfg_path, max_token=args.max_token,
                  provider=args.provider, temperature=args.temperature)

    tc = TokenCounter(llm); tc.set_cur_tag(args.tag)
    rtl_txt = _read(args.rtl)

    if gen_bench:
        sys_msg = ChatMessage(role=MessageRole.SYSTEM, content=SYSTEM_PROMPT)
        user_raw = USER_RTL_PROMPT_TEMPLATE.format(
            target_name=args.top, example_spec=EXAMPLE_SPEC, rtl_text="{{RTL_PLACEHOLDER}}"
        )
        static = user_raw.replace("{{RTL_PLACEHOLDER}}", "")
        reserve = 3000
        rem = max(args.tokens - reserve, 2000)
        trimmed = _soft_trim(tc, [(static, 2000), (rtl_txt, rem)], args.tokens)
        user_final = user_raw.replace("{{RTL_PLACEHOLDER}}", trimmed[1])

        user_msg = ChatMessage(role=MessageRole.USER, content=user_final)
        resp, cnt = tc.count_chat([sys_msg, user_msg], llm=llm)
        spec_md = (resp.message.content or "").strip()
        try:
            spec_md = reformat_json_string(spec_md)
        except Exception:
            pass

        os.makedirs(out_dir, exist_ok=True)
        with open(out_md, "w", encoding="utf-8") as f:
            f.write(spec_md + ("" if spec_md.endswith("\n") else "\n"))
        spec_txt = md_to_txt(spec_md)
        with open(out_txt, "w", encoding="utf-8") as f:
            f.write(spec_txt + ("" if spec_txt.endswith("\n") else "\n"))
    else:
        cnt = None  # no spec LLM call in lib-only mode

    json_out_path = None
    if gen_lib:
        os.makedirs(out_dir, exist_ok=True)  # ensure dir exists for json-only too
        json_out_path = generate_rtl_json_spec(
            llm=llm,
            rtl_path=args.rtl,
            rtl_text=rtl_txt,
            top_module_name=args.top,
            out_path=out_json
        )

    stats = {"model": llm.metadata.model_name, "provider": args.provider}
    if cnt is not None:
        stats.update({"in_tokens": cnt.in_token_cnt, "out_tokens": cnt.out_token_cnt})
        try:
            cost = tc.token_cost
            stats["estimated_usd"] = round(
                cnt.in_token_cnt * cost.in_token_cost_per_token +
                cnt.out_token_cnt * cost.out_token_cost_per_token, 6
            )
        except Exception:
            pass
    with open(os.path.splitext(args.out)[0] + ".usage.json", "w", encoding="utf-8") as f:
        json.dump(stats, f, indent=2)

    if cnt is not None:
        logger.info(f"Usage: in {cnt.in_token_cnt} tokens, out {cnt.out_token_cnt} tokens")
        if "estimated_usd" in stats:
            logger.info(f"Estimated cost: ${stats['estimated_usd']:.4f}")

if __name__ == "__main__":
    main()
